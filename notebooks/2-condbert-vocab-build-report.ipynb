{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text De-Toxification, part II: Building Vocabulary for condBERT\n",
    "### Robert Chen, B20-AI\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **condBERT** model does not need to be trained, but we need a solid corpus for it to show acceptable results. Gladly, there are already a lot of datasets that suit this task specifically. In our case, we are going to use *Jigsaw* dataset, which was already prepared by SkolTech team and the initial *ParaNMT* dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/train\n",
      "/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/test\n",
      "--2023-11-05 20:51:45--  https://raw.githubusercontent.com/s-nlp/detox/main/emnlp2021/data/train/train_toxic\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10514256 (10M) [text/plain]\n",
      "Saving to: ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/train/train_toxic’\n",
      "\n",
      "train_toxic         100%[===================>]  10,03M  21,6MB/s    in 0,5s    \n",
      "\n",
      "2023-11-05 20:51:45 (21,6 MB/s) - ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/train/train_toxic’ saved [10514256/10514256]\n",
      "\n",
      "--2023-11-05 20:51:45--  https://raw.githubusercontent.com/s-nlp/detox/main/emnlp2021/data/train/train_normal\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10973711 (10M) [text/plain]\n",
      "Saving to: ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/train/train_normal’\n",
      "\n",
      "train_normal        100%[===================>]  10,46M  2,78MB/s    in 3,9s    \n",
      "\n",
      "2023-11-05 20:51:50 (2,67 MB/s) - ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/train/train_normal’ saved [10973711/10973711]\n",
      "\n",
      "--2023-11-05 20:51:50--  https://raw.githubusercontent.com/s-nlp/detox/main/emnlp2021/data/test/test_10k_toxic\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 687032 (671K) [text/plain]\n",
      "Saving to: ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/test/test_10k_toxic’\n",
      "\n",
      "test_10k_toxic      100%[===================>] 670,93K  2,93MB/s    in 0,2s    \n",
      "\n",
      "2023-11-05 20:51:50 (2,93 MB/s) - ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/test/test_10k_toxic’ saved [687032/687032]\n",
      "\n",
      "--2023-11-05 20:51:50--  https://raw.githubusercontent.com/s-nlp/detox/main/emnlp2021/data/test/test_10k_normal\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 814429 (795K) [text/plain]\n",
      "Saving to: ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/test/test_10k_normal’\n",
      "\n",
      "test_10k_normal     100%[===================>] 795,34K  1,83MB/s    in 0,4s    \n",
      "\n",
      "2023-11-05 20:51:51 (1,83 MB/s) - ‘/home/b0b/Stuff/Personal/Uni/InnoStuff/F23/Practical Machine Learning/PMLDL-text-detox/data/interim/condbert_vocab/test/test_10k_normal’ saved [814429/814429]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!usr/bin/bash\n",
    "DATA_DIR=\"../data\"\n",
    "! bash $DATA_DIR/clean_vocab.sh\n",
    "! bash $DATA_DIR/download_jigsaw.sh\n",
    "! bash $DATA_DIR/download_paranmt.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to process *ParaNMT* and *ParaDetox* datasets and add them to the existing train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paranmt_path = '../data/raw/filtered.tsv'\n",
    "\n",
    "train_toxic = '../data/interim/condbert_vocab/train/train_toxic'\n",
    "train_normal = '../data/interim/condbert_vocab/train/train_normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process the *ParaNMT* dataset, we need to gather all texts with high toxicity scores into `train_toxic` dataset and put the rest into `train_normal` dataset. We will put all reference texts with `ref_tox` higher than 0.8, the cutoff for neutral dataset will be 0.2. The decision to use only reference texts in the training is motivated by better stability, since the translation can affect fluency of the model significantly. Also we will need to separate the punctuation marks with a whitespace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paranmt_df = pd.read_csv(paranmt_path, sep=\"\\t\", index_col=0)\n",
    "tokenizer = WordPunctTokenizer()\n",
    "toxic_ref = list(map(lambda x: f'{\" \".join(tokenizer.tokenize(x))}\\n', paranmt_df[paranmt_df.ref_tox >= 0.8]['reference'].tolist()))\n",
    "with open(train_toxic, 'a') as f:\n",
    "    f.writelines(toxic_ref)\n",
    "    \n",
    "neutral_ref = list(map(lambda x: f'{\" \".join(tokenizer.tokenize(x))}\\n', paranmt_df[paranmt_df.ref_tox <= 0.2]['reference'].tolist()))\n",
    "with open(train_normal, 'a') as f:\n",
    "    f.writelines(neutral_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculating the toxicity of each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the toxicity, we will score each token by the frequency it appears in the chosen corpus opposed to the number of appearances in another corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramSalienceCalculator:\n",
    "    def __init__(self, tox_corpus, norm_corpus):\n",
    "        ngrams = (1, 1)\n",
    "        self.vectorizer = CountVectorizer(ngram_range=ngrams)\n",
    "        tox_matrix = self.vectorizer.fit_transform(tox_corpus)\n",
    "        self.tox_vocab = self.vectorizer.vocabulary_\n",
    "        self.tox_count = np.sum(tox_matrix, axis=0)\n",
    "        \n",
    "        norm_matrix = self.vectorizer.fit_transform(norm_corpus)\n",
    "        self.norm_vocab = self.vectorizer.vocabulary_\n",
    "        self.norm_count = np.sum(norm_matrix, axis=0)\n",
    "        \n",
    "    def calculate(self, feature, attr='tox', eps=0.5):\n",
    "        assert attr in ['tox', 'norm']\n",
    "        tox_cnt = self.tox_count[0, self.tox_vocab[feature]] if feature in self.tox_vocab else 0.0\n",
    "        norm_cnt = self.norm_count[0, self.norm_vocab[feature]] if feature in self.norm_vocab else 0.0\n",
    "        if attr == 'tox':\n",
    "            return (tox_cnt + eps) / (norm_cnt + eps)\n",
    "        else:\n",
    "            return (norm_cnt + eps) / (tox_cnt + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the counter for words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160243"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter()\n",
    "for filename in [train_toxic, train_normal]:\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            for token in line.strip().split():\n",
    "                cnt[token] += 1\n",
    "len(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use every word that has at least 1 occurrence in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160243"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {word for word, count in cnt.most_common() if count > 0}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating corpora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_normal, 'r') as normal, open(train_toxic, 'r') as toxic:\n",
    "    tox_corpus = [' '.join([word if word in vocab else '<unk>' for word in line.strip().split()]) for line in toxic.readlines()]\n",
    "    norm_corpus = [' '.join([word if word in vocab else '<unk>' for word in line.strip().split()]) for line in normal.readlines()]\n",
    "\n",
    "pos_words = '../data/interim/condbert_vocab/positive_words.txt'\n",
    "neg_words = '../data/interim/condbert_vocab/negative_words.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the toxicity scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = NgramSalienceCalculator(tox_corpus, norm_corpus)\n",
    "used_ngrams = set()\n",
    "threshold = 4\n",
    "with open(pos_words, 'w') as pos_file, open(neg_words, 'w') as neg_file:\n",
    "    for gram in set(calc.tox_vocab.keys()).union(set(calc.norm_vocab.keys())):\n",
    "        if gram in used_ngrams:\n",
    "            continue\n",
    "        used_ngrams.add(gram)\n",
    "        tox_score, norm_score = calc.calculate(gram, attr='tox'), calc.calculate(gram, attr='norm')\n",
    "        if tox_score > threshold:\n",
    "            neg_file.writelines(f'{gram}\\n')\n",
    "        elif norm_score > threshold:\n",
    "            pos_file.writelines(f'{gram}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training word2coeff with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Logistic Regression to predict the toxicity of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=1000, n_jobs=-1))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "X_train, y_train = tox_corpus + norm_corpus, [1] * len(tox_corpus) + [0] * len(norm_corpus)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136125,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = pipe[1].coef_[0]\n",
    "coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2coef = {word: coeffs[idx] for word, idx in pipe[0].vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/interim/condbert_vocab/word2coef.pkl', 'wb') as f:\n",
    "    pickle.dump(word2coef, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Labelling tokens by toxicity using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_cnt, norm_cnt = defaultdict(lambda: 1), defaultdict(lambda: 1)\n",
    "for text in tox_corpus:\n",
    "    for token in tokenizer.encode(text):\n",
    "        toxic_cnt[token] += 1\n",
    "\n",
    "for text in norm_corpus:\n",
    "    for token in tokenizer.encode(text):\n",
    "        norm_cnt[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_toxicities = [toxic_cnt[i] / (norm_cnt[i] + toxic_cnt[i]) for i in range(len(tokenizer.vocab))]\n",
    "with open('../data/interim/condbert_vocab/token_toxicities.txt', 'w') as f:\n",
    "    for score in token_toxicities:\n",
    "        f.write(str(score) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
